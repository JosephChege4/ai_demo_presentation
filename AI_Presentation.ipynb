{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f9146a-c6f3-4a78-b3fb-0d262492e87c",
   "metadata": {},
   "source": [
    "# Sentence Window Retrieval - AI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e8b1a-e9e7-4141-a4d2-72fb31a7e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import (\n",
    "    MetadataReplacementPostProcessor,\n",
    "    SentenceTransformerRerank,\n",
    ")\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # Create node parser\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "\n",
    "    # Set global settings (this replaces ServiceContext)\n",
    "    Settings.llm = llm\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.node_parser = node_parser\n",
    "\n",
    "    # Create or load the index\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir)\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # Postprocessor to insert full sentence windows\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "\n",
    "    # Reranker to reorder top results using a smarter model\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    # Build query engine with both enhancements\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k,\n",
    "        node_postprocessors=[postproc, rerank],\n",
    "    )\n",
    "\n",
    "    return sentence_window_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b5bb36f-97f9-4e03-bd4e-3ceb635a868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI \n",
    "from llama_index.core import Settings\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./XC1-Character-Guide.pdf\"]\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "08492fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "index = build_sentence_window_index(\n",
    "    [document],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e78e0-7765-4037-a5fa-63b711dab5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite team is Fiora (Seven), Melia, and Riki, where I control Melia. What are the pros and cons of this team? Consider the AI of the non-player controlled units, chain attacks, buffs, debuffs, and overall synergy.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The team of Fiora (Seven), Melia, and Riki has several pros and cons. One advantage is that Seven can function well as a tank, drawing aggro and providing survivability support for Melia, who has low survivability. Riki, as mentioned, is rated as one of the best teammates for Melia due to their synergy. Additionally, Melia's flexibility with passive buffs and in Chain Attacks can benefit the team overall.\n",
       "\n",
       "However, a potential drawback is that Melia struggles with filling the Party Gauge efficiently, which can hinder the team's Chain Attack potential. Additionally, while Seven and Melia have good synergy, Riki's AI-controlled healing abilities may not always align perfectly with the team's needs, especially in terms of generating aggro or maximizing Chain Attack damage.\n",
       "\n",
       "Overall, the team of Fiora (Seven), Melia, and Riki can work well together due to their individual strengths and synergies, but may face challenges in optimizing Chain Attacks and Party Gauge filling efficiency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the best possible party in Xenoblade Chronicles. Consider all possible teams?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The best possible party in Xenoblade Chronicles would likely include Seven and Shulk due to their high damage output, powerful Arts, and unique abilities that make them versatile and effective in various situations. Additionally, Seven's ability to damage Mechon without requiring Enchant and Shulk's positioning-dependent Arts add strategic depth to the party composition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is Sharla considered the worst party member? Can you argue for her placement as the best?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Sharla is considered the worst party member due to her low DPS, lack of synergy with certain teammates like Reyn and Dunban, and her limitations in building the Party Gauge effectively. She hinders damage output and Chain Attacks with certain party compositions, making her less desirable in many situations. However, some may argue for her placement as the best due to her sustainability and ability to provide healing and support, which can be crucial for long-term battles and keeping the party alive without additional assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is Reyn considered the best party member? Can you argue for his placement as the best?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Reyn is considered the best party member due to his fantastic party support capabilities, including debuffs like Paralysis, Agility Down, and Strength Down, which significantly reduce enemy damage output. He also excels in AoE damage and aggro draw, possesses incredible Burst damage potential, and can reach high dodge rates despite his low Agility. While he has weaknesses like low sustained damage, his overall potential is often underestimated, making a strong case for his placement as the best party member."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n",
    "\n",
    "with open('./generated_questions.txt') as file:\n",
    "    for line in file:\n",
    "        question = line.strip()\n",
    "        print(question)\n",
    "        display_response(query_engine.query(question))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
